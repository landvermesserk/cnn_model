{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f0a0be-62e9-4480-8828-d894ce21e00d",
   "metadata": {},
   "source": [
    "# Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e19945-1066-4ab4-81c7-5f1ed3ca58c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==2.0 numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20438b2-f594-461f-8196-a7d6cc7b64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1bf647-b876-4278-baa2-d306959c434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "from numba import jit\n",
    "import timeit\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2519575e-4865-4106-8751-0a348e5f0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverwriteError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18466078-2ef0-4892-94dc-a0212db5cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowSizeError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47709a8-1f8f-494b-81db-7d3f49777e0c",
   "metadata": {},
   "source": [
    "# Forward and Backward for MLP networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ac0114-ccdb-4ec4-9ae1-99907861dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit\n",
    "def extend_input_by_one_vector(x_input: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    height, width = x_input.shape\n",
    "    vector_extended = np.ones((height + 1, width))\n",
    "    vector_extended[:height, :width] = x_input\n",
    "    return vector_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24a9e46-8c81-4a72-80fb-5ebb3681fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit\n",
    "def pre_process_input(x_input: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    x_input = (x_input - np.mean(x_input)) / np.std(x_input)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bb2925-7812-4a62-b0e2-a76136da4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit\n",
    "def apply_sigmoid(x_input: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05bbd9d1-e3fa-4863-9b14-36f4628664e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit\n",
    "def log_entropy(y_pred: np.ndarray, \n",
    "                y_label: np.ndarray) -> np.float16:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    return (-np.sum(y_label * np.log(y_pred) + (1 - y_label) * np.log(1 - y_pred))).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fde4159-9634-475f-89a2-7cd9030b1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit\n",
    "def forward_pass(x_input: np.ndarray,\n",
    "                weight_matrix_input_layer: np.ndarray,\n",
    "                weight_matrix_first_hidden_layer: np.ndarray,\n",
    "                weight_matrix_second_hidden_layer: np.ndarray,\n",
    "                weight_matrix_output_layer: np.ndarray) -> Tuple[np.ndarray]:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    a1 = np.dot(weight_matrix_input_layer, x_input)\n",
    "    h1 = apply_sigmoid(a1)\n",
    "    h1 = extend_input_by_one_vector(h1)\n",
    "    a2 = np.dot(weight_matrix_first_hidden_layer, h1)\n",
    "    h2 = apply_sigmoid(a2)\n",
    "    h2 = extend_input_by_one_vector(h2)\n",
    "    a3 = np.dot(weight_matrix_second_hidden_layer, h2)\n",
    "    h3 = apply_sigmoid(a3)\n",
    "    h3 = extend_input_by_one_vector(h3)\n",
    "    a4 = np.dot(weight_matrix_output_layer, h3)\n",
    "    h4 = apply_sigmoid(a4)\n",
    "\n",
    "    return (a1, h1, a2, h2, a3, h3, a4, h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c426dcd-fcc2-4be5-8812-f3f97697c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "lambda_reg = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b7c4b7-d444-4cb5-947e-c763037ef1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([\n",
    "                   [1,-2, -1],\n",
    "                   [2 ,4 ,5],\n",
    "                   [5,7,-4],\n",
    "                   [-2,7,0],\n",
    "                   [100, 20, -9]\n",
    "                   ])\n",
    "#print(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc4ecd8-e332-4a12-8055-135ad46d51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = pre_process_input(x_input=x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902a2c6e-f7de-4fd9-9f15-6d32dc12cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.transpose(x_input)\n",
    "x_input = extend_input_by_one_vector(x_input=x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60da9d90-2e76-4900-97e4-d1f84ceb28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = x_input.shape[1]\n",
    "num_iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29b2f09-aad7-4c08-a338-796f14daaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = np.transpose(np.array([\n",
    "    [1, 0, 0], \n",
    "    [0, 1, 1], \n",
    "    [0, 0, 1], \n",
    "    [1, 1, 0],\n",
    "    [1, 0, 0]\n",
    "]))\n",
    "#print(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc5b672e-9665-4b93-a054-86df07f1eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = 3\n",
    "hidden_layer = [16, 16, 8]\n",
    "output_dimension = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37509137-f05a-4736-9d00-115fedbd7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix_input_layer = np.random.randn(hidden_layer[0], input_dimension + 1)\n",
    "weight_matrix_first_hidden_layer = np.random.randn(hidden_layer[1], hidden_layer[0] + 1)\n",
    "weight_matrix_second_hidden_layer = np.random.randn(hidden_layer[2], hidden_layer[1] + 1)\n",
    "weight_matrix_output_layer = np.random.randn(output_dimension, hidden_layer[2] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5df8f3-7dfe-4f94-abc8-e54a5945754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(log_entropy(y_pred=h2[:,i], y_label=y_label[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9e0820e-0a43-4d01-86a5-670d229bea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.079195261001587\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for k in range(num_iterations):\n",
    "    a1, h1, a2, h2, a3, h3, a4, h4 = forward_pass(x_input=x_input,\n",
    "                                          weight_matrix_input_layer=weight_matrix_input_layer,\n",
    "                                          weight_matrix_first_hidden_layer=weight_matrix_first_hidden_layer,\n",
    "                                          weight_matrix_second_hidden_layer=weight_matrix_second_hidden_layer,\n",
    "                                          weight_matrix_output_layer=weight_matrix_output_layer)\n",
    "    update_weights_four = 0\n",
    "    update_weights_three = 0\n",
    "    update_weights_two = 0\n",
    "    update_weights_one = 0\n",
    "    for i in range(num_samples):\n",
    "        \n",
    "        backward_one = h4[:,i] - y_label[:,i]\n",
    "        update_weights_four += np.stack([backward_one[j] * h3[:,i] for j in range(output_dimension)], axis=0).flatten()\n",
    "        \n",
    "        backward_two = np.dot(np.transpose(backward_one), weight_matrix_output_layer[:,:-1])\n",
    "        backward_three = backward_two * (h3[:-1,i] * (1 - h3[:-1,i]))\n",
    "        update_weights_three += np.stack([backward_three[j] * h2[:,i] for j in range(hidden_layer[2])], axis=0).flatten()\n",
    "        \n",
    "        backward_four = np.dot(np.transpose(backward_three), weight_matrix_second_hidden_layer[:,:-1])\n",
    "        backward_five = backward_four * (h2[:-1,i] * (1 - h2[:-1,i]))\n",
    "        update_weights_two += np.stack([backward_five[j] * h1[:,i] for j in range(hidden_layer[1])], axis=0).flatten()\n",
    "        \n",
    "        backward_six = np.dot(np.transpose(backward_five), weight_matrix_first_hidden_layer[:,:-1])\n",
    "        backward_seven = backward_six * (h1[:-1,i] * (1 - h1[:-1,i]))\n",
    "        update_weights_one += np.stack([backward_seven[j] * x_input[:,i] for j in range(hidden_layer[0])], axis=0).flatten()\n",
    "    \n",
    "    update_weights_one = -1/num_samples * update_weights_one - 2 * lambda_reg * np.sum(weight_matrix_input_layer.flatten())\n",
    "    update_weights_two = -1/num_samples * update_weights_two - 2 * lambda_reg * np.sum(weight_matrix_first_hidden_layer.flatten())\n",
    "    update_weights_three = -1/num_samples * update_weights_three - 2 * lambda_reg * np.sum(weight_matrix_second_hidden_layer.flatten())\n",
    "    update_weights_four = -1/num_samples * update_weights_four - 2 * lambda_reg * np.sum(weight_matrix_output_layer.flatten())\n",
    "\n",
    "    weight_matrix_output_layer = (weight_matrix_output_layer.flatten() \\\n",
    "                                  + learning_rate * update_weights_four).reshape(weight_matrix_output_layer.shape)\n",
    "    weight_matrix_second_hidden_layer = (weight_matrix_second_hidden_layer.flatten() \\\n",
    "                                  + learning_rate * update_weights_three).reshape(weight_matrix_second_hidden_layer.shape)\n",
    "    weight_matrix_first_hidden_layer = (weight_matrix_first_hidden_layer.flatten() \\\n",
    "                                  + learning_rate * update_weights_two).reshape(weight_matrix_first_hidden_layer.shape)\n",
    "    weight_matrix_input_layer = (weight_matrix_input_layer.flatten() \\\n",
    "                                  + learning_rate * update_weights_one).reshape(weight_matrix_input_layer.shape)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f18d438-96fc-4629-9c93-27cdc5d9022a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.98062679e-01 3.59900374e-03 4.81311450e-03 9.93920598e-01\n",
      "  9.97596868e-01]\n",
      " [5.43001331e-03 9.93479407e-01 7.61350294e-03 9.91937684e-01\n",
      "  4.29352539e-04]\n",
      " [1.53121084e-03 9.96068231e-01 9.95319796e-01 4.67335595e-03\n",
      "  2.61778786e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c5e6e-1d0c-4d26-b2ca-08b1e114cf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28d65e0d-0668-47a0-a30d-28f5ae0fa855",
   "metadata": {},
   "source": [
    "# Forward and Backward for CNN networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f26be-20da-48ac-9746-2518ce589026",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cab3e517-21a5-4a6f-bf5d-d7bbe793bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def batch_normalization_forward(array: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Substraction of mean and division by standard deviation.\n",
    "\n",
    "    Args:\n",
    "        array: The input array.\n",
    "    Returns:\n",
    "        Normalized vector.\n",
    "    \n",
    "    \"\"\"\n",
    "    return (array - np.mean(array)) / np.std(array)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "889af4d9-3d58-4c14-ae0b-1513fe8f493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186 253 247 ... 188  82 110]\n"
     ]
    }
   ],
   "source": [
    "array = np.random.randint(0, 255, 13 * 13 * 16)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62649055-32fe-4762-b1c2-a48eab4e717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.318934679031372\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "bnf = batch_normalization_forward(array)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9ff9b94-1e42-4450-8c0a-6563e0ec5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def batch_normalization_backward_(array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Subtraction of mean and division by standard deviation with faster computation.\n",
    "\n",
    "    Args:\n",
    "        array: The input array.\n",
    "    Returns:\n",
    "        Normalized vector.\n",
    "    \"\"\"\n",
    "    array_length = array.shape[0]\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    \n",
    "    # Compute the first term (diagonal adjustment)\n",
    "    diag_term = (np.eye(array_length) * array_length - 1) / (array_length * std)\n",
    "    \n",
    "    # Compute the second term (outer product-based)\n",
    "    centered = array - mean\n",
    "    outer_product_term = np.outer(centered, centered) / (array_length * std**3)\n",
    "    \n",
    "    # The final result\n",
    "    derivative_normalization = diag_term - outer_product_term\n",
    "    \n",
    "    return derivative_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1917c111-4d4d-4390-af83-a17e5c41f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def batch_normalization_backward(array: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Substraction of mean and division by standard deviation.\n",
    "\n",
    "    Args:\n",
    "        array: The input array.\n",
    "    Returns:\n",
    "        Normalized vector.\n",
    "    \n",
    "    \"\"\"\n",
    "    array_length = array.shape[0]\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    derivative_normalization = np.zeros((array_length, array_length))\n",
    "\n",
    "    for i in range(array_length):\n",
    "        for j in range(i, array_length):\n",
    "            derivative_normalization[i, j] = (int(i==j) * array_length - 1) / (array_length * std)\\\n",
    "            - (array[i] - mean) * (array[j] - mean) / (array_length * std * std * std)\n",
    "            derivative_normalization[j, i] = derivative_normalization[i, j]\n",
    "    \n",
    "    return derivative_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64957168-f887-4904-8f13-13c2c7f18f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(0, 255, 13 * 13 * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c611e08-1c79-424e-8a1e-1daeafa752f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11031746864318848\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "bnb = batch_normalization_backward(array)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1b76f-078e-4958-b0bc-e00c7e3c215b",
   "metadata": {},
   "source": [
    "## Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2daeecb3-cb91-4c6e-9d1f-6918e6b8a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def max_pooling_forward(array: np.ndarray,\n",
    "               window_size: Tuple[int]=(2,2)) -> Tuple[np.ndarray]:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        array:\n",
    "        window_size:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    row, col = array.shape\n",
    "    row_pool, col_pool = row // 2, col // 2\n",
    "    if row % window_size[0]:\n",
    "        row_pool += 1\n",
    "    if col % window_size[1]:\n",
    "        col_pool += 1\n",
    "\n",
    "    max_pooling_array_argmax = np.zeros((row_pool, col_pool), dtype=np.int64)\n",
    "    max_pooling_array_max = np.zeros((row_pool, col_pool))\n",
    "    max_pooling_array_argmax_global_indices = np.zeros((row_pool, col_pool), dtype=np.int64)\n",
    "    for i in range(row_pool):\n",
    "        for j in range(col_pool):\n",
    "            max_pooling_array_argmax[i, j] = np.argmax(array[i*window_size[0]:(i+1)*window_size[0]\\\n",
    "                                                       ,j*window_size[1]:(j+1)*window_size[1]])\n",
    "            max_pooling_array_max[i, j] = np.max(array[i*window_size[0]:(i+1)*window_size[0]\\\n",
    "                                                       ,j*window_size[1]:(j+1)*window_size[1]])\n",
    "\n",
    "            max_pooling_array_argmax_global_indices[i, j] = ((2 * i \\\n",
    "                                                              + max_pooling_array_argmax[i,j] // 2) \\\n",
    "                                                             * col + 2 * j + max_pooling_array_argmax[i,j] % 2)\n",
    "\n",
    "    return max_pooling_array_argmax_global_indices.flatten(), max_pooling_array_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4486cac2-bf30-42c1-b642-de3c51db2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def max_pooling_backward(array: np.ndarray,\n",
    "                        array_max_indices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        array:\n",
    "        array_max_indiices:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    row, col = array.shape\n",
    "    len_indices = len(array_max_indices)\n",
    "    result = np.zeros((len_indices, row * col))\n",
    "    for i in range(len_indices):\n",
    "        for j in range(row * col):\n",
    "            result[i,j] = int(array_max_indices[i] == j)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a624da8b-4ed5-4a27-9bd1-9bdf7f9548be",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(0, 255, (8, 28, 28, 1))\n",
    "#print(array[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c9ce3c-48b3-4e79-970f-b578f545a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel, row, col, batch_size = array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68244e9b-49fb-44ad-bf0b-479ee9e1aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.845829486846924\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "res = [[max_pooling_forward(array[i, : , :, j]) for i in range(channel)] for j in range(batch_size)]\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362e4e0a-59a5-46bf-8740-089ae968c8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4724555015563965\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mpb = max_pooling_backward(array[0,:,:,0], res[0][0][0])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbd1675-7674-4813-bff5-5fd9bdd0484f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Alternative max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53468126-7d9a-431f-95a8-608074915fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling_forward(array: np.ndarray,\n",
    "               window_size: int=2) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        array:\n",
    "        window_size:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    row, col = array.shape\n",
    "    if row % window_size:\n",
    "        #array = np.vstack((array, np.array([array[-1,:]])))\n",
    "        array = np.vstack((array, -np.inf * np.ones((1, col))))\n",
    "        \n",
    "    if col % window_size:\n",
    "        row, col = array.shape\n",
    "        #array = np.hstack((array, np.transpose(np.array([array[:,-1]]))))\n",
    "        array = np.hstack((array, -np.inf * np.ones((row, 1))))\n",
    "\n",
    "    row, col = array.shape\n",
    "    row_output = row // window_size\n",
    "    col_output = col // window_size\n",
    "    array_window_reshaped = array[:row_output*window_size, :col_output*window_size] \\\n",
    "    .reshape(row_output, window_size, col_output, window_size).swapaxes(1,2) \\\n",
    "    .reshape(-1, window_size ** 2)\n",
    "\n",
    "    array_window_reshaped_argmax = array_window_reshaped.argmax(axis=1).reshape(row_output, col_output)\n",
    "    array_window_reshaped_max = array_window_reshaped.max(axis=1).reshape(row_output, col_output)\n",
    "\n",
    "    #max_pooling_array_argmax_global_indices \\\n",
    "    #            = np.array([[((2 * i + int(array_window_reshaped_argmax[i,j] // 2)) * col + 2 * j + array_window_reshaped_argmax[i,j] % 2) \\\n",
    "    #           for j in range(col_output)] \\\n",
    "    #          for i in range(row_output)]).flatten()\n",
    "\n",
    "    return array_window_reshaped_max#, max_pooling_array_argmax_global_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71bf67f9-b25a-42df-b2a4-0ea2b3d180a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(0, 255, (1001, 1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d526f60c-06ce-4c7c-a83f-de2a639f1623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23,  23,  58, ...,  68, 165, 250],\n",
       "       [ 71, 172,  32, ..., 123, 184, 153],\n",
       "       [173, 146,  83, ..., 112,   1, 206],\n",
       "       ...,\n",
       "       [197, 231, 133, ..., 117, 223,  85],\n",
       "       [147,  37,   4, ..., 119,  73,  59],\n",
       "       [ 10, 220, 140, ..., 227, 105, 237]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00167a8f-3f2d-412b-a53b-528363dea770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06948995590209961\n",
      "[[172. 165. 170. ... 215. 184. 250.]\n",
      " [218. 207. 224. ... 247. 112. 206.]\n",
      " [219. 252. 161. ... 180. 163. 253.]\n",
      " ...\n",
      " [214. 191.  81. ... 251. 171. 215.]\n",
      " [231. 228. 193. ... 175. 223.  85.]\n",
      " [220. 140. 188. ...  78. 227. 237.]]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "x = max_pooling_forward(array)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c808cd58-6e0d-4164-8388-a54e4fd785f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m max_pooling_forward(\u001b[43mmat\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mat' is not defined"
     ]
    }
   ],
   "source": [
    "max_pooling_forward(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66226b1-04ef-406e-8cfc-b780730055cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pooling_forward(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e79e49-ef9f-4b69-95e9-919869a5069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pooling_forward(mat)[[0, 1],[1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a164db-e81c-4ab9-93f5-4bdbcdc0ecfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b027535-0960-429e-88a3-55a97b5c4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.random.randint(0, 10, (5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3787d3b-3c2a-42c2-91a4-3e24d197e77e",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad5fe9a7-372f-44f7-a848-ff9359f5a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7750820433310169\n",
      "[[ 0.44629861  1.78712402 -0.50723247]\n",
      " [ 0.09509415 -1.62199944 -0.98359166]\n",
      " [ 0.93698612  1.05682671  0.60621636]]\n"
     ]
    }
   ],
   "source": [
    "array = np.random.randint(0, 255, (6, 6))\n",
    "#print(array)\n",
    "filter_convolution = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "filter_convolution = np.random.randn(3,3)\n",
    "offset = np.random.rand(1)[0]\n",
    "print(offset)\n",
    "print(filter_convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c160b8-7291-44b8-b8dd-4843dda98262",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_shape = array.shape\n",
    "filter_shape = filter_convolution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b47618d3-4485-4f27-8423-692396a6c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def create_base_conv_vector(array_shape: Tuple[int], \n",
    "                              filter_conv: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        array: The shape of the matrix on which\n",
    "               we want to apply a  convolution.\n",
    "        filter_conv: The filter matrix. \n",
    "    Returns:\n",
    "        The basic convolutional vector from which we will \n",
    "        construct the convolution matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    filter_conv_row, filter_conv_col = filter_conv.shape\n",
    "    conv_vector = np.zeros(array_shape[0] * array_shape[1])\n",
    "    for i in range(filter_conv_row):\n",
    "        conv_vector[array_shape[1]*i:array_shape[1]*i+filter_conv_row] = filter_conv[i,:]\n",
    "    return conv_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5f49aa-23bc-4cf4-85e6-a7e1054f6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def create_convolution_matrix(array_shape: Tuple[int], \n",
    "                              filter_conv: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        array: The shape of the matrix on which\n",
    "               we want to apply a  convolution.\n",
    "        filter_conv: The filter matrix. \n",
    "    Returns:\n",
    "        The expanded filter matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    filter_conv_row, filter_conv_col = filter_conv.shape\n",
    "    matrix_conv_rep = np.zeros(((array_shape[0] - filter_conv_row + 1) * (array_shape[1] - filter_conv_col + 1) \\\n",
    "                                , array_shape[0] * array_shape[1]))\n",
    "    base_conv_vector = create_base_conv_vector(array_shape, filter_conv)\n",
    "    for i in range((array_shape[1] - filter_conv_col + 1) * (array_shape[0] - filter_conv_row + 1)):\n",
    "        matrix_conv_rep[i,:] = np.roll(base_conv_vector, int(i // (array_shape[0] - filter_conv_row + 1)) * array_shape[1] \\\n",
    "        + i % (array_shape[0] - filter_conv_row + 1))\n",
    "\n",
    "    return matrix_conv_rep\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd5a061f-b6a0-41b6-950f-7e6fcaa56714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8901357650756836\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "convolution_matrix = create_convolution_matrix(array.shape, filter_convolution)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb150ec6-5625-43e6-89df-a95efaad8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_forward(array: np.ndarray,\n",
    "                       conv_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    return np.dot(conv_matrix, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9121106e-9e66-4b86-98ef-8b98092821f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9109060764312744\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "convolution_matrix = create_convolution_matrix(array.shape, filter_convolution)\n",
    "conv_forward = convolution_forward(array.flatten(), convolution_matrix) \\\n",
    "    .reshape((array_shape[0] - filter_shape[0] + 1, array_shape[1] - filter_shape[1] + 1)) \\\n",
    "    + offset\n",
    "max_pool_forward = max_pooling_forward(conv_forward)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca310f4-221e-4569-b74f-dc7707f3ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def convolution_backward_update(array: np.ndarray,\n",
    "                        filter_conv_shape: Tuple[int] = (3, 3)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    array_shape = array.shape\n",
    "    filter_conv_update_matrix = np.zeros(((array_shape[0] - filter_conv_shape[0] + 1) \\\n",
    "                                   * (array_shape[1] - filter_conv_shape[1] + 1) \\\n",
    "                                , filter_conv_shape[0] * filter_conv_shape[1]))\n",
    "    index = 0\n",
    "    for i in range(array_shape[0] - filter_conv_shape[0] + 1):\n",
    "        for j in range(array_shape[1] - filter_conv_shape[1] + 1):\n",
    "            filter_conv_update_matrix[index] = array[i:(i+3), j:(j+3)].flatten()\n",
    "            index += 1\n",
    "    \n",
    "\n",
    "    return filter_conv_update_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b80208-ea27-4cb7-92d7-c7426a59eeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8693954944610596\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "filter_conv_shape = filter_convolution.shape\n",
    "conv_backward = convolution_backward_update(array, \n",
    "                    filter_conv_shape)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fae820-590c-4880-ad86-4bcbf2fe9be0",
   "metadata": {},
   "source": [
    "## Backpropagation_update_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2be34577-f53b-43e9-80fa-432f731d4bf7",
   "metadata": {},
   "source": [
    "           W11 X1 + W12 X2 + b1\n",
    "1 / 2 *    W21 X1 + W22 X2 + b2\n",
    "           W31 X1 + W32 X2 + b3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "adb6219c-d5fd-4fbe-88e9-2bf861223538",
   "metadata": {},
   "source": [
    "Derivative: \n",
    "\n",
    "K1 0 0 K2 0 0 K3 0 0 ... 1 0 0\n",
    "0 K1 0 0 K2 0 0 K3 0 ... 0 1 0\n",
    "0 0 K1 0 0 K2 0 0 K3 ... 0 0 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47ce419e-cc11-4ffd-a741-d845a8e55790",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def backpropagation_update_matrix(array: np.ndarray,\n",
    "                                 num_filters_old: int,\n",
    "                                 num_filters_new: int,\n",
    "                                 array_conv_shape: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    filter_conv_update_matrix = np.zeros((array_conv_shape * array_conv_shape * num_filters_new, \\\n",
    "                                         (filter_col * filter_row) * num_filters_old * num_filters_new + num_filters_new))\n",
    "    index = 0\n",
    "    for k in range(num_filters_old):\n",
    "        array_sliced = array[k, :,:]\n",
    "        local_update_matrix = convolution_backward_update(array=array_sliced)\n",
    "        for l in range(num_filters_new):\n",
    "            filter_conv_update_matrix[l * array_conv_shape*array_conv_shape:(l+1) * array_conv_shape * array_conv_shape,\\\n",
    "            (num_filters_new * k + l) * filter_col * filter_row\\\n",
    "            :(num_filters_new * k + l + 1) * filter_col * filter_row] \\\n",
    "            = local_update_matrix\n",
    "\n",
    "    for k in range(num_filters_new-1):\n",
    "        filter_conv_update_matrix[k * array_conv_shape * array_conv_shape:(k + 1) * array_conv_shape * array_conv_shape\\\n",
    "        ,-(num_filters_new-k):-(num_filters_new-k-1)] = 1\n",
    "\n",
    "    k = num_filters_new - 1\n",
    "    filter_conv_update_matrix[k * array_conv_shape * array_conv_shape:(k + 1) * array_conv_shape * array_conv_shape\\\n",
    "        ,-1:] = 1\n",
    "    \n",
    "    return 1 / num_filters_old * filter_conv_update_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f831f4-e32b-4e69-80d7-aaf6e4a67ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b81268-2a79-4f9f-bba6-44a66bc5decb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdb96531-09f3-47f4-bdac-76cdb4a3eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters_old = 4\n",
    "num_filters_new = 3\n",
    "filter_row, filter_col = [3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5832f2e-98d2-40be-beaa-a7ff369890e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_shape = (4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d29665e-4460-4982-a909-fe1ca35d4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_conv_shape = array_shape[0] - 3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72bc7e27-41f4-4d47-aed2-0c7ee95859f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(0, 255, (num_filters_old, array_shape[0], array_shape[1]))\n",
    "filter_convolution = np.random.randn(num_filters_new, num_filters_old, filter_row, filter_col)\n",
    "offset = np.random.rand(num_filters_new, 1).flatten()\n",
    "#print(offset)\n",
    "#print(filter_convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85e475e0-4a9b-42c1-99be-94da7d349e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 3, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_convolution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb280f33-9795-476c-a8cb-543bf4934dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8293671607971191\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "update_matrix = backpropagation_update_matrix(array=array,\n",
    "                             num_filters_old=num_filters_old,\n",
    "                             num_filters_new=num_filters_new,\n",
    "                             array_conv_shape=array_conv_shape)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1887d655-9878-4f38-b106-6a08c3eadba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_matrix[-4:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5646f-e2e7-4b4a-a53e-e43b27fee51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8640f5e-0d2b-48c5-a12c-189165b77916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640c6db-9e0b-4bed-8e66-710742473f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8613a-7d4e-4dd0-995a-0f3a9c058a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9dcc7d3-b2ba-48cf-8a2b-fef28d39e4c8",
   "metadata": {},
   "source": [
    "## Full network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1c5b8-85f3-4f71-a1a8-6fbd4259b60b",
   "metadata": {},
   "source": [
    "### Specify input and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad066a77-51e4-4645-954f-6aec5f1ae15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def normalize_input_image(array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    We normalize the input image tensor by dividing by 255.\n",
    "    \"\"\"\n",
    "    return 1 / 255 * array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17bc041a-2961-4c86-85f9-e82683931996",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def create_convolution_matrix_stacked(filter_convolution_sliced: np.ndarray,\n",
    "                                     row_array: int,\n",
    "                                     col_array: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    num_filter, row_filter, col_filter = filter_convolution_sliced.shape\n",
    "    row_res, col_res = (row_array - row_filter + 1, col_array - col_filter + 1)\n",
    "    dimesion_row, dimension_col = (row_res * col_res, row_array * col_array)\n",
    "    convolution_matrix_stacked = np.zeros((dimesion_row, dimension_col * num_filter))\n",
    "    for j in range(num_filter):\n",
    "        convolution_matrix_stacked[:, dimension_col * j: dimension_col * (j+1)]\\\n",
    "        = create_convolution_matrix((row_array, col_array), filter_convolution_sliced[j,:,:])\n",
    "\n",
    "    return convolution_matrix_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c7ca339-7130-4ea9-952e-e8b3dea957b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def forward_backward_step_convolution_module(filter_convolution: np.array,\n",
    "                                            offset: np.ndarray,\n",
    "                                            array: np.array,\n",
    "                                            num_filters_old: int,\n",
    "                                            num_filters_new: int) -> Tuple[np.ndarray]:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    num_filter_old, row_array, col_array = array.shape\n",
    "    row_conv, col_conv = [row_array - filter_conv_row + 1, col_array - filter_conv_col + 1]\n",
    "    row_pool, col_pool = [row_conv // 2, col_conv // 2]\n",
    "    matrix_convolution_max_pooling_backward = np.zeros((row_pool ** 2 * num_filters_new, row_array ** 2 * num_filter_old))\n",
    "    feature_map_final_flatten = np.zeros(row_pool ** 2 * num_filters_new)\n",
    "    max_pooling_backward_matrix = np.zeros((row_pool ** 2 * num_filters_new, row_conv ** 2 * num_filters_new))\n",
    "    for j in range(num_filters_new):\n",
    "        filter_convolution_sliced = filter_convolution[j,:,:,:]\n",
    "        convolution_matrix_stacked = create_convolution_matrix_stacked(filter_convolution_sliced=filter_convolution_sliced,\n",
    "                                                                row_array=row_array,\n",
    "                                                               col_array=col_array)\n",
    "        feature_vector_stacked = array.flatten()\n",
    "        feature_map = 1 / num_filters_old * np.dot(convolution_matrix_stacked, feature_vector_stacked) + offset[j]\n",
    "        feature_map_reshaped = feature_map.reshape(row_conv, col_conv)\n",
    "        feature_map_max_pooling_indices, feature_map_max_pooling = max_pooling_forward(array=feature_map_reshaped)\n",
    "        feature_map_max_pooling_flatten = feature_map_max_pooling.flatten()\n",
    "        feature_map_final_flatten[row_pool ** 2 * j:row_pool ** 2 * (j+1)] = feature_map_max_pooling_flatten\n",
    "        mpb = max_pooling_backward(array=feature_map_reshaped, array_max_indices=feature_map_max_pooling_indices)\n",
    "        max_pooling_backward_matrix[row_pool ** 2 * j:row_pool ** 2 * (j+1), row_conv ** 2 * j:row_conv ** 2 * (j+1)] = mpb\n",
    "        matrix_convolution_max_pooling_backward[row_pool ** 2 * j:row_pool ** 2 * (j+1),:] = 1 / num_filters_old * np.dot(mpb, convolution_matrix_stacked)\n",
    "    bnb = batch_normalization_backward(feature_map_final_flatten) \n",
    "    array_batch_normalization = batch_normalization_forward(feature_map_final_flatten).reshape((num_filters_new, row_pool, col_pool))\n",
    "    norm_backpropagation = np.dot(bnb, matrix_convolution_max_pooling_backward)\n",
    "    norm_max_pooling_backpropagation = np.dot(bnb, max_pooling_backward_matrix)\n",
    "    return array_batch_normalization, norm_backpropagation, norm_max_pooling_backpropagation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766aa39-c874-4105-8fa3-4ff5bca08168",
   "metadata": {},
   "source": [
    "### Example cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "45288a85-3dc8-4cb0-8d1a-572e2451a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = [1, 8, 4]\n",
    "num_iterations = 1\n",
    "learning_rate = 0.1\n",
    "lambda_reg = 0.01\n",
    "num_samples = 1\n",
    "y_label = np.transpose(np.array([\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "]))\n",
    "print(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "204a12c6-e2c6-4710-b9c4-d1c8a53324ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 0\n",
    "input_size = (num_filters[stage], 30, 30)\n",
    "array = np.random.randint(0, 255, input_size)\n",
    "array = normalize_input_image(array=array)\n",
    "filter_conv_row, filter_conv_col = (3, 3)\n",
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage+1]\n",
    "filter_convolution_one = np.random.randn(num_filters_new, num_filters_old, filter_conv_row, filter_conv_col)\n",
    "offset_one = np.random.rand(num_filters_new, 1).flatten()\n",
    "stage = 1\n",
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage+1]\n",
    "filter_convolution_two = np.random.randn(num_filters_new, num_filters_old, filter_conv_row, filter_conv_col)\n",
    "offset_two = np.random.rand(num_filters_new, 1).flatten()\n",
    "input_dimension = 144\n",
    "hidden_layer = [8]\n",
    "output_dimension = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "18b9356b-b069-4798-a332-6a551fd41e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix_input_layer = np.random.randn(hidden_layer[0], input_dimension + 1)\n",
    "weight_matrix_output_layer = np.random.randn(output_dimension, hidden_layer[0] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dd188-ddfb-40df-8a01-f369b4ed62eb",
   "metadata": {},
   "source": [
    "### First convolution, max_pooling and batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c12dd7-89f2-4db5-8a12-d4158fe5cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    stage = 0\n",
    "    input_size = (num_filters[stage], 30, 30)\n",
    "    filter_conv_row, filter_conv_col = (3, 3)\n",
    "    num_filters_old = num_filters[stage]\n",
    "    num_filters_new = num_filters[stage+1]\n",
    "    num_filter_old, row_array, col_array = array.shape\n",
    "    row_conv, col_conv = [row_array - filter_conv_row + 1, col_array - filter_conv_col + 1]\n",
    "    row_pool, col_pool = [row_conv // 2, col_conv // 2]\n",
    "    array_one, derivative_one, norm_max_pooling_backward_one = forward_backward_step_convolution_module(filter_convolution=filter_convolution_one,\n",
    "                                                                                                        offset=offset_one,\n",
    "                                            array=array,\n",
    "                                            num_filters_old=num_filter_old,\n",
    "                                            num_filters_new=num_filters_new)\n",
    "    update_matrix_conv_one = backpropagation_update_matrix(array=array,\n",
    "                                 num_filters_old=num_filter_old,\n",
    "                                 num_filters_new=num_filters_new,\n",
    "                                 array_conv_shape=row_conv)\n",
    "    stage = 1\n",
    "    num_filters_old = num_filters[stage]\n",
    "    num_filters_new = num_filters[stage+1]\n",
    "    print(num_filter_old, num_filters_new)\n",
    "    num_filter_old, row_array, col_array = array_one.shape\n",
    "    row_conv, col_conv = [row_array - filter_conv_row + 1, col_array - filter_conv_col + 1]\n",
    "    row_pool, col_pool = [row_conv // 2, col_conv // 2]\n",
    "    array_two, derivative_two, norm_max_pooling_backward_two = forward_backward_step_convolution_module(filter_convolution=filter_convolution_two,\n",
    "                                                                                                        offset=offset_two,\n",
    "                                            array=array_one,\n",
    "                                            num_filters_old=num_filter_old,\n",
    "                                            num_filters_new=num_filters_new)\n",
    "    update_matrix_conv_two = backpropagation_update_matrix(array=array_one,\n",
    "                                 num_filters_old=num_filter_old,\n",
    "                                 num_filters_new=num_filters_new,\n",
    "                                 array_conv_shape=row_conv)\n",
    "    array_three = array_two.flatten()\n",
    "    array_three = np.expand_dims(array_three, axis=0)\n",
    "    input_dimension = array_three.shape[1]\n",
    "    print(\"----------------MLP-----------------\")\n",
    "    hidden_layer = [8]\n",
    "    output_dimension = 10\n",
    "    x_input = np.transpose(array_three)\n",
    "    x_input = extend_input_by_one_vector(x_input=x_input)\n",
    "    k = 0\n",
    "    a1, h1, a2, h2 = forward_pass(x_input=x_input,\n",
    "                                              weight_matrix_input_layer=weight_matrix_input_layer,\n",
    "                                              weight_matrix_output_layer=weight_matrix_output_layer)\n",
    "    print(h2)\n",
    "    update_weights_two = 0\n",
    "    update_weights_one = 0\n",
    "    i = 0\n",
    "    backward_one = h2[:,i] - y_label[:,i]\n",
    "    update_weights_two += np.stack([backward_one[j] * h1[:,i] for j in range(output_dimension)], axis=0).flatten()\n",
    "    \n",
    "    update_weights_two = -1/1 * update_weights_two\n",
    "    \n",
    "    backward_two = np.dot(np.transpose(backward_one), weight_matrix_output_layer[:,:-1])\n",
    "    backward_three = backward_two * (h1[:-1,i] * (1 - h1[:-1,i]))\n",
    "    update_weights_one += np.stack([backward_three[j] * x_input[:,i] for j in range(hidden_layer[0])], axis=0).flatten()\n",
    "    \n",
    "    update_weights_one = -1/1 * update_weights_one\n",
    "    \n",
    "    backward_four = np.dot(np.transpose(backward_three), weight_matrix_input_layer[:,:-1])\n",
    "    weight_matrix_output_layer = (weight_matrix_output_layer.flatten() \\\n",
    "                                      + learning_rate * update_weights_two).reshape(weight_matrix_output_layer.shape)\n",
    "    weight_matrix_input_layer = (weight_matrix_input_layer.flatten() \\\n",
    "                                      + learning_rate * update_weights_one).reshape(weight_matrix_input_layer.shape)\n",
    "    \n",
    "    \n",
    "    backpropagation_second_norm_max_pooling = np.dot(backward_four, norm_max_pooling_backward_two)\n",
    "    update_second_conv_weights = np.dot(backpropagation_second_norm_max_pooling, update_matrix_conv_two)\n",
    "    update_second_conv_weights = -1/1 * update_second_conv_weights\n",
    "    update_second_conv_weights_reshaped = update_second_conv_weights[:-num_filters[2]].reshape(num_filters[2], num_filters[1], 3, 3)\n",
    "    filter_convolution_two = filter_convolution_two + learning_rate * update_second_conv_weights_reshaped\n",
    "    offset_two = offset_two + learning_rate * update_second_conv_weights[-num_filters[2]:]\n",
    "    \n",
    "    \n",
    "    backpropagation_first_norm_max_pooling = np.dot(np.dot(backward_four, derivative_two), norm_max_pooling_backward_one)\n",
    "    update_first_conv_weights = np.dot(backpropagation_first_norm_max_pooling, update_matrix_conv_one)\n",
    "    update_first_conv_weights = -1/1 * update_first_conv_weights\n",
    "    update_first_conv_weights_reshaped = update_first_conv_weights[:-num_filters[1]].reshape(num_filters[1], num_filters[0], 3, 3)\n",
    "    filter_convolution_one = filter_convolution_one + learning_rate * update_first_conv_weights_reshaped\n",
    "    offset_one = offset_one + learning_rate * update_first_conv_weights[-num_filters[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d976560-8ea5-4e81-bd8e-eb740f2f08df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06445cc2-8958-45a8-943c-46f396e59c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf65049e-3e92-4385-83b5-85acef279100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "018133bc-dfd8-4ed5-98a5-faa326decb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b793926-5d57-4cf4-ac6b-77b7d3bdea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (num_filters[stage], 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d1caa9db-0be0-4d22-be52-a027cb708b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(0, 255, input_size)\n",
    "array = normalize_input_image(array=array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "40a62682-61dd-4f9b-a707-cc98526d1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_conv_row, filter_conv_col = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c55c02f-1422-4239-adec-45b11eaaf25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2065bf8a-8ddd-4dc6-8e1e-a97ab442a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_convolution_one = np.random.randn(num_filters_new, num_filters_old, filter_conv_row, filter_conv_col)\n",
    "offset_one = np.random.rand(num_filters_new, 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8d50ccd0-88cc-4382-98e7-384466878812",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter_old, row_array, col_array = array.shape\n",
    "row_conv, col_conv = [row_array - filter_conv_row + 1, col_array - filter_conv_col + 1]\n",
    "row_pool, col_pool = [row_conv // 2, col_conv // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9917ff9c-564b-475f-83ee-85788cf870ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.48169469833374\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "array_one, derivative_one, norm_max_pooling_backward_one = forward_backward_step_convolution_module(filter_convolution=filter_convolution_one,\n",
    "                                                                                                    offset=offset_one,\n",
    "                                        array=array,\n",
    "                                        num_filters_old=num_filter_old,\n",
    "                                        num_filters_new=num_filters_new)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "26a3f9c2-ae0f-400c-8b07-62eb1006b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_matrix_conv_one = backpropagation_update_matrix(array=array,\n",
    "                             num_filters_old=num_filter_old,\n",
    "                             num_filters_new=num_filters_new,\n",
    "                             array_conv_shape=row_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "43233a41-defb-444b-a081-9d75c7df14b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 14, 14)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_one.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07119d4-c380-4b2e-9cee-e53003284984",
   "metadata": {},
   "source": [
    "### Second convolution, max_pooling and batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "51eb242a-ef0c-4841-9e19-d82583f07cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5664b375-687e-4722-ad46-52b1d8d2d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n"
     ]
    }
   ],
   "source": [
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage+1]\n",
    "print(num_filter_old, num_filters_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7a756589-1db4-43f7-a13c-a16dfb246405",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_convolution_two = np.random.randn(num_filters_new, num_filters_old, filter_conv_row, filter_conv_col)\n",
    "offset_two = np.random.rand(num_filters_new, 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e5bc3dfc-daf6-4e42-9a22-a2927e4763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter_old, row_array, col_array = array_one.shape\n",
    "row_conv, col_conv = [row_array - filter_conv_row + 1, col_array - filter_conv_col + 1]\n",
    "row_pool, col_pool = [row_conv // 2, col_conv // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "488fee92-9208-444a-a558-38bf36f5b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08735275268554688\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "array_two, derivative_two, norm_max_pooling_backward_two = forward_backward_step_convolution_module(filter_convolution=filter_convolution_two,\n",
    "                                                                                                    offset=offset_two,\n",
    "                                        array=array_one,\n",
    "                                        num_filters_old=num_filter_old,\n",
    "                                        num_filters_new=num_filters_new)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b4f3de42-e445-4206-b4d6-31fe2ca8ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_matrix_conv_two = backpropagation_update_matrix(array=array_one,\n",
    "                             num_filters_old=num_filter_old,\n",
    "                             num_filters_new=num_filters_new,\n",
    "                             array_conv_shape=row_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "896efb52-a19c-456d-9519-2b41a43375d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_three = array_two.flatten()\n",
    "array_three = np.expand_dims(array_three, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aac139f6-d790-422d-8e9e-238276c72772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_three.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf7c3e6-85ad-432e-9b54-5a62ce1e66b6",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "42eb3939-5a0c-46c0-a8ba-3840c628291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def extend_input_by_one_vector(x_input: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    height, width = x_input.shape\n",
    "    vector_extended = np.ones((height + 1, width))\n",
    "    vector_extended[:height, :width] = x_input\n",
    "    return vector_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42f1cb72-ab72-4371-bbd0-024ccae65120",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def apply_sigmoid(x_input: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "34e3eb5d-3d39-4150-81e0-7529cc5bf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def forward_pass(x_input: np.ndarray,\n",
    "                weight_matrix_input_layer: np.ndarray,\n",
    "                weight_matrix_output_layer: np.ndarray) -> Tuple[np.ndarray]:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    a1 = np.dot(weight_matrix_input_layer, x_input)\n",
    "    h1 = apply_sigmoid(a1)\n",
    "    h1 = extend_input_by_one_vector(h1)\n",
    "    a2 = np.dot(weight_matrix_output_layer, h1)\n",
    "    h2 = apply_sigmoid(a2)\n",
    "\n",
    "    return (a1, h1, a2, h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3316604c-74ec-48f0-a190-ca2030c2b0c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array_three' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_dimension \u001b[38;5;241m=\u001b[39m \u001b[43marray_three\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m hidden_layer \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m8\u001b[39m]\n\u001b[1;32m      3\u001b[0m output_dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array_three' is not defined"
     ]
    }
   ],
   "source": [
    "input_dimension = array_three.shape[1]\n",
    "hidden_layer = [8]\n",
    "output_dimension = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "84d1a650-9bd1-4178-b675-d43dabc902f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.transpose(array_three)\n",
    "x_input = extend_input_by_one_vector(x_input=x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e39e91f-a29d-4435-9ffc-24bbd05b91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight_matrix_input_layer = np.random.randn(hidden_layer[0], input_dimension + 1)\n",
    "#weight_matrix_output_layer = np.random.randn(output_dimension, hidden_layer[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e6c1e230-8ae7-4107-bb02-dd5891ff2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5f20954c-00f0-439e-ac1c-7e4512b05772",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, h1, a2, h2 = forward_pass(x_input=x_input,\n",
    "                                          weight_matrix_input_layer=weight_matrix_input_layer,\n",
    "                                          weight_matrix_output_layer=weight_matrix_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "270a79b2-4e86-4b49-bdad-914a1145239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0987318 ],\n",
       "       [0.5672034 ],\n",
       "       [0.00873734],\n",
       "       [0.94498739],\n",
       "       [0.87578339],\n",
       "       [0.12611772],\n",
       "       [0.28211042],\n",
       "       [0.22324196],\n",
       "       [0.61287511],\n",
       "       [0.05421787]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b3652-0f09-4bd7-86b0-e1d764bfa6c8",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b6af0eef-ef65-4dbe-bf5a-65323ff6d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_weights_two = 0\n",
    "update_weights_one = 0\n",
    "i = 0\n",
    "backward_one = h2[:,i] - y_label[:,i]\n",
    "update_weights_two += np.stack([backward_one[j] * h1[:,i] for j in range(output_dimension)], axis=0).flatten()\n",
    "\n",
    "backward_two = np.dot(np.transpose(backward_one), weight_matrix_output_layer[:,:-1])\n",
    "backward_three = backward_two * (h1[:-1,i] * (1 - h1[:-1,i]))\n",
    "update_weights_one += np.stack([backward_three[j] * x_input[:,i] for j in range(hidden_layer[0])], axis=0).flatten()\n",
    "\n",
    "backward_four = np.dot(np.transpose(backward_three), weight_matrix_input_layer[:,:-1])\n",
    "weight_matrix_output_layer = (weight_matrix_output_layer.flatten() \\\n",
    "                                  + learning_rate * update_weights_two).reshape(weight_matrix_output_layer.shape)\n",
    "weight_matrix_input_layer = (weight_matrix_input_layer.flatten() \\\n",
    "                                  + learning_rate * update_weights_one).reshape(weight_matrix_input_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "7fd53da9-c4bf-4870-9c37-3bfb5e356e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward_four.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "09ec95a1-c0b8-43c4-92fe-9541ff5ab399",
   "metadata": {},
   "outputs": [],
   "source": [
    "backpropagation_second_norm_max_pooling = np.dot(backward_four, norm_max_pooling_backward_two)\n",
    "update_second_conv_weights = np.dot(backpropagation_second_norm_max_pooling, update_matrix_conv_two)\n",
    "update_second_conv_weights_reshaped = update_second_conv_weights[:-num_filters[2]].reshape(num_filters[2], num_filters[1], 3, 3)\n",
    "filter_convolution_two = filter_convolution_two + learning_rate * update_second_conv_weights_reshaped\n",
    "offset_two = offset_two + learning_rate * update_second_conv_weights[-num_filters[2]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "7eecc7d7-97c5-403b-8ce4-243ec337074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filter_convolution_two.shape)\n",
    "#print(update_second_conv_weights[:-num_filters[2]].reshape(num_filters[2], num_filters[1], 3, 3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7cdb6872-07d0-4cdc-98b3-086eda4d4c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#offset_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "6065cb6b-336e-42d4-94dd-798d7a278445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_second_conv_weights[-num_filters[2]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "21cac667-63d4-42d4-bcd9-df1646c17a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filter_convolution_two.shape)\n",
    "#print(offset_two.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "71af8052-5aa0-4af4-9a85-bb194b120ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_convolution_two = filter_convolution_two + learning_rate * update_second_conv_weights_reshaped\n",
    "#offset_two = offset_two + learning_rate * update_second_conv_weights[-num_filters[2]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "6ed6772a-6956-4f85-aeb6-4866e8c40e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filter_convolution_two.shape)\n",
    "#print(offset_two.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "b8ff565e-96cb-46ce-93d7-b7edd65e4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert update_second_conv_weights.shape[0] == num_filters[2] * num_filters[1] * 9 + num_filters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "24902573-9d73-4731-bacd-10d671b76d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "backpropagation_first_norm_max_pooling = np.dot(np.dot(backward_four, derivative_two), norm_max_pooling_backward_one)\n",
    "update_first_conv_weights = np.dot(backpropagation_first_norm_max_pooling, update_matrix_conv_one)\n",
    "update_first_conv_weights_reshaped = update_first_conv_weights[:-num_filters[1]].reshape(num_filters[1], num_filters[0], 3, 3)\n",
    "filter_convolution_one = filter_convolution_one + learning_rate * update_first_conv_weights_reshaped\n",
    "offset_one = offset_one + learning_rate * update_first_conv_weights[-num_filters[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ff60c1c4-0021-4831-83ce-cf61bdd3097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert update_first_conv_weights.shape[0] == num_filters[1] * num_filters[0] * 9 + num_filters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "719bfd1f-b5fc-4a28-8b2f-991c5e0bc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_first_conv_weights_reshaped = update_first_conv_weights[:-num_filters[1]].reshape(num_filters[1], num_filters[0], 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "d0533b08-4a80-4e2a-8a7b-823ad7e0b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filter_convolution_one.shape)\n",
    "#print(offset_one.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "8657db9e-55e4-4c9b-92a0-0fd55a64373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_convolution_one = filter_convolution_one + learning_rate * update_first_conv_weights_reshaped\n",
    "#offset_one = offset_one + learning_rate * update_first_conv_weights[-num_filters[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "9f1ea087-c195-4a29-80ce-04f656473909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filter_convolution_one.shape)\n",
    "#print(offset_one.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "36fba395-c17a-4d28-aed8-7d5ff8d36c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_first_conv_weights[:-num_filters[1]].reshape(num_filters[0], num_filters[1], 3, 3).swapaxes(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d205ed-c1a5-446f-b762-9af32428e5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca0aa5e4-29f1-4ef0-a1ff-0062425b50a4",
   "metadata": {},
   "source": [
    "# Make it clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1966155-1135-49b7-9fb9-fb3a7f4a4200",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8efda-703c-4ff0-b383-a087b6147109",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a94291e-8de1-4e6f-8283-3db80fbde88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def batch_normalization_forward(array: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Substraction of mean and division by standard deviation.\n",
    "\n",
    "    Args:\n",
    "        array: The input array.\n",
    "    Returns:\n",
    "        Normalized vector.\n",
    "    \n",
    "    \"\"\"\n",
    "    return (array - np.mean(array)) / np.std(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dd2cc20-1616-4502-8d87-2c4d3477ac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7  63 130 ... 117  46 220]\n",
      "1.3185274600982666\n"
     ]
    }
   ],
   "source": [
    "array = np.random.randint(0, 255, 13 * 13 * 16)\n",
    "print(array)\n",
    "start_time = time.time()\n",
    "bnf = batch_normalization_forward(array)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc7e65-b07b-4f11-a6b2-abd0f57511ec",
   "metadata": {},
   "source": [
    "### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9d27d5a-4ae3-402f-9b0b-211aea8185da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def batch_normalization_backward(array: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Substraction of mean and division by standard deviation.\n",
    "\n",
    "    Args:\n",
    "        array: The input array.\n",
    "    Returns:\n",
    "        Normalized vector.\n",
    "    \n",
    "    \"\"\"\n",
    "    array_length = array.shape[0]\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    derivative_normalization = np.zeros((array_length, array_length))\n",
    "\n",
    "    for i in range(array_length):\n",
    "        for j in range(i, array_length):\n",
    "            derivative_normalization[i, j] = (int(i==j) * array_length - 1) / (array_length * std)\\\n",
    "            - (array[i] - mean) * (array[j] - mean) / (array_length * std * std * std)\n",
    "            derivative_normalization[j, i] = derivative_normalization[i, j]\n",
    "    \n",
    "    return derivative_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "409635cc-869d-4a6e-9b91-7fd8375bce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5954625606536865\n"
     ]
    }
   ],
   "source": [
    "array = np.random.randint(0, 255, 13 * 13 * 16)\n",
    "start_time = time.time()\n",
    "bnb = batch_normalization_backward(array)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6cc79-5cc9-46d4-a5ac-96c9e9a7c233",
   "metadata": {},
   "source": [
    "## Max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba7a6b-6490-40d6-b4cf-dafc204dd7d5",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42b2ac9f-e9fa-489f-acb0-b2b418000b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def max_pooling_forward(array: np.ndarray,\n",
    "               window_size: Tuple[int]=(2,2)) -> Tuple[np.ndarray]:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        array:\n",
    "        window_size:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    channel, row, col = array.shape\n",
    "    row_pool, col_pool = row // 2, col // 2\n",
    "    if row % window_size[0]:\n",
    "        row_pool += 1\n",
    "    if col % window_size[1]:\n",
    "        col_pool += 1\n",
    "\n",
    "    max_pooling_array_argmax = np.zeros((channel, row_pool, col_pool), dtype=np.int64)\n",
    "    max_pooling_array_max = np.zeros((channel, row_pool, col_pool))\n",
    "    max_pooling_array_argmax_global_indices = np.zeros((channel, row_pool, col_pool), dtype=np.int64)\n",
    "    for c in range(channel):\n",
    "        for i in range(row_pool):\n",
    "            for j in range(col_pool):\n",
    "                max_pooling_array_argmax[c, i, j] = np.argmax(array[c, i*window_size[0]:(i+1)*window_size[0]\\\n",
    "                                                           ,j*window_size[1]:(j+1)*window_size[1]])\n",
    "                max_pooling_array_max[c, i, j] = np.max(array[c, i*window_size[0]:(i+1)*window_size[0]\\\n",
    "                                                           ,j*window_size[1]:(j+1)*window_size[1]])\n",
    "    \n",
    "                max_pooling_array_argmax_global_indices[c, i, j] = ((2 * i \\\n",
    "                                                                  + max_pooling_array_argmax[c, i,j] // 2) \\\n",
    "                                                                 * col + 2 * j + max_pooling_array_argmax[c, i,j] % 2)\n",
    "\n",
    "    return max_pooling_array_argmax_global_indices.reshape(channel, row_pool * row_pool), max_pooling_array_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e605f822-f085-4620-a5b7-2b27a7814dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(0, 255, (32, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd3105ee-fa02-4850-b561-e7ab9354b8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ebe6626-3be1-406f-89ac-f821ba9118ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1962323188781738\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "a, b = max_pooling_forward(array=array)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1245da-68fe-4b28-bc64-4afba1826c8b",
   "metadata": {},
   "source": [
    "### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7fa7c54-f9f8-44b5-8ba1-83fa5664eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def max_pooling_backward(array_shape: Tuple[int],\n",
    "                        array_max_indices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        array:\n",
    "        array_max_indices:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    channel, row, col = array_shape\n",
    "    size_feature_map = row * col\n",
    "    _, num_max_indices = array_max_indices.shape\n",
    "\n",
    "    array_backpropagation = np.zeros((channel * num_max_indices, channel * size_feature_map))\n",
    "\n",
    "    for c in range(channel):\n",
    "        array_max_indices_sliced = array_max_indices[c,:]\n",
    "        for i in range(num_max_indices):\n",
    "            for j in range(row * col):\n",
    "                array_backpropagation[c * num_max_indices  + i, c * size_feature_map + j] = int(array_max_indices_sliced[i] == j)\n",
    "\n",
    "    return array_backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2102fcf9-5cb0-4fa9-a85f-f27f1cf01d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(0, 255, (2, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99a55310-682c-4761-be27-1e2dea73825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00014281272888183594\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "max_indices, pooling_array = max_pooling_forward(array=array)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2b954e4-fba5-4b7d-9ca6-4245645d3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42421555519104004\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mpb = max_pooling_backward(array.shape, max_indices)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d13d9a-e358-41db-b298-0c4a89a02d4b",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f5b3c-6192-4459-a014-d19ff13cfdb6",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b75eef7-eae6-4edb-8cd4-7d1174f923e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def create_base_conv_vector(array_shape: Tuple[int], \n",
    "                              filter_convolution: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        array: The shape of the matrix on which\n",
    "               we want to apply a  convolution.\n",
    "        filter_conv: The filter matrix. \n",
    "    Returns:\n",
    "        The basic convolutional vector from which we will \n",
    "        construct the convolution matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    filter_conv_row, filter_conv_col = filter_convolution.shape\n",
    "    conv_vector = np.zeros(array_shape[0] * array_shape[1])\n",
    "    for i in range(filter_conv_row):\n",
    "        conv_vector[array_shape[1]*i:array_shape[1]*i+filter_conv_row] = filter_convolution[i,:]\n",
    "    return conv_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc7c4434-d3da-4099-9ef2-761a378fb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def create_convolution_matrix(array_shape: Tuple[int], \n",
    "                              filter_convolution: np.ndarray,\n",
    "                              offset: np.array) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        array: The shape of the matrix on which\n",
    "               we want to apply a  convolution.\n",
    "        filter_conv: The filter matrix. \n",
    "    Returns:\n",
    "        The expanded filter matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _, row, col = array_shape\n",
    "    size_old_feature_map = row * col\n",
    "    num_filter_new, num_filter_old, filter_conv_row, filter_conv_col = filter_convolution.shape\n",
    "    feature_map_conv_row_col = row - filter_conv_row + 1\n",
    "    size_new_feature_map = feature_map_conv_row_col * feature_map_conv_row_col\n",
    "    \n",
    "    matrix_conv_rep = np.zeros((size_new_feature_map * num_filter_new \\\n",
    "                                , size_old_feature_map * num_filter_old + 1))\n",
    "    \n",
    "    for i in range(num_filter_new):\n",
    "        for j in range(num_filter_old):\n",
    "            base_conv_vector = create_base_conv_vector((row, col), filter_convolution[i, j])\n",
    "            for k in range(size_new_feature_map):\n",
    "                matrix_conv_rep[i * size_new_feature_map + k, j * size_old_feature_map:(j+1) * size_old_feature_map] \\\n",
    "                = np.roll(base_conv_vector, int(k // (feature_map_conv_row_col)) * col \\\n",
    "                + k % feature_map_conv_row_col)\n",
    "        matrix_conv_rep[i * size_new_feature_map:(i+1) * size_new_feature_map,-1] = offset[i]\n",
    "    return matrix_conv_rep            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "566296ba-6ef4-4d8c-9e3b-3b6acf35e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def convolution_forward(array: np.ndarray,\n",
    "                        conv_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    array = array.astype(np.float32)\n",
    "    conv_matrix = conv_matrix.astype(np.float32)\n",
    "    return np.dot(conv_matrix, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dbbd374-dfc9-4913-b326-8b45568c3816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59641424 0.42442125 0.46302074 0.95165906 0.27260962 0.85000078\n",
      " 0.22879956 0.83222946 0.63712579 0.39152218 0.88167221 0.35683683\n",
      " 0.53198938 0.21811308 0.87212711 0.0788774 ]\n",
      "(16, 1, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "array = np.random.randint(0, 255, (1, 30, 30))\n",
    "#print(array)\n",
    "num_filter_new, num_filter_old = (16 ,1)\n",
    "filter_convolution = np.random.randn(num_filter_new, num_filter_old, 3, 3)\n",
    "offset = np.random.rand(num_filter_new)\n",
    "print(offset)\n",
    "print(filter_convolution.shape)\n",
    "array_shape = array.shape\n",
    "filter_shape = filter_convolution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4eab73a9-7a50-4b2a-ac1e-063b2bef0827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "array_shape = array.shape\n",
    "print(array_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "999894b1-a83d-4992-84db-b9c9c1dc350e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.058684825897217\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "convolution_matrix = create_convolution_matrix(array.shape, \n",
    "                                               filter_convolution,\n",
    "                                              offset)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b1fa726-bcdd-42e0-9379-f2f7b6d1cd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12544, 901)\n"
     ]
    }
   ],
   "source": [
    "print(convolution_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d1cee25-c385-4696-abfd-827af2622f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_extended_by_one = np.concatenate([array.flatten(), np.array([1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f64b5f6-0592-4760-a9e8-41d57b4f6eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5814740657806396\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "a = convolution_forward(array=array_extended_by_one, conv_matrix=convolution_matrix)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5668986-fa73-4454-8c34-fd5f839067ec",
   "metadata": {},
   "source": [
    "### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae8069a5-7084-4a0b-addb-6be9e01fa5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def convolution_backward(convolution_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    return convolution_matrix[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11a6f05c-285c-4cf0-9348-ea7a826ddd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23185157775878906\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "a = convolution_backward(convolution_matrix=convolution_matrix)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef82f22-2dd1-43d3-9703-45011edc1dd8",
   "metadata": {},
   "source": [
    "### Update convolution filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa5dca2d-2b1f-46d5-9a5d-515f736b8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def convolution_backward_update(array: np.ndarray,\n",
    "                        filter_conv_shape: Tuple[int] = (3, 3)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    array_shape = array.shape\n",
    "    filter_conv_update_matrix = np.zeros(((array_shape[0] - filter_conv_shape[0] + 1) \\\n",
    "                                   * (array_shape[1] - filter_conv_shape[1] + 1) \\\n",
    "                                , filter_conv_shape[0] * filter_conv_shape[1]))\n",
    "    index = 0\n",
    "    for i in range(array_shape[0] - filter_conv_shape[0] + 1):\n",
    "        for j in range(array_shape[1] - filter_conv_shape[1] + 1):\n",
    "            filter_conv_update_matrix[index] = array[i:(i+3), j:(j+3)].flatten()\n",
    "            index += 1\n",
    "    \n",
    "\n",
    "    return filter_conv_update_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2fe86be-cc72-4b75-a2fd-b9180f1ee7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def backpropagation_update_matrix(array: np.ndarray,\n",
    "                                 num_filters_old: int,\n",
    "                                 num_filters_new: int,\n",
    "                                 array_conv_shape: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    filter_conv_update_matrix = np.zeros((array_conv_shape * array_conv_shape * num_filters_new, \\\n",
    "                                         (filter_col * filter_row) * num_filters_old * num_filters_new + num_filters_new))\n",
    "    index = 0\n",
    "    for k in range(num_filters_old):\n",
    "        array_sliced = array[k, :,:]\n",
    "        local_update_matrix = convolution_backward_update(array=array_sliced)\n",
    "        for l in range(num_filters_new):\n",
    "            filter_conv_update_matrix[l * array_conv_shape*array_conv_shape:(l+1) * array_conv_shape * array_conv_shape,\\\n",
    "            (num_filters_new * k + l) * filter_col * filter_row\\\n",
    "            :(num_filters_new * k + l + 1) * filter_col * filter_row] \\\n",
    "            = local_update_matrix\n",
    "\n",
    "    for k in range(num_filters_new-1):\n",
    "        filter_conv_update_matrix[k * array_conv_shape * array_conv_shape:(k + 1) * array_conv_shape * array_conv_shape\\\n",
    "        ,-(num_filters_new-k):-(num_filters_new-k-1)] = 1\n",
    "\n",
    "    k = num_filters_new - 1\n",
    "    filter_conv_update_matrix[k * array_conv_shape * array_conv_shape:(k + 1) * array_conv_shape * array_conv_shape\\\n",
    "        ,-1:] = 1\n",
    "    \n",
    "    return 1 / num_filters_old * filter_conv_update_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb6940ee-f9f8-4662-b99b-aa352eb45781",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters_old = 16\n",
    "num_filters_new = 8\n",
    "filter_row, filter_col = [3, 3]\n",
    "array_shape = (4, 4)\n",
    "array_conv_shape = array_shape[0] - 3 + 1\n",
    "array = np.random.randint(0, 255, (num_filters_old, array_shape[0], array_shape[1]))\n",
    "filter_convolution = np.random.randn(num_filters_new, num_filters_old, filter_row, filter_col)\n",
    "offset = np.random.rand(num_filters_new, 1).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a4b126b-1060-4603-b03c-1082a93d5bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3108851909637451\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "update_matrix = backpropagation_update_matrix(array=array,\n",
    "                             num_filters_old=num_filters_old,\n",
    "                             num_filters_new=num_filters_new,\n",
    "                             array_conv_shape=array_conv_shape)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3128a6-a47e-452f-9f43-a152a9cd092f",
   "metadata": {},
   "source": [
    "## Initial image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a13f4f34-fdf7-44c7-b180-422008e16dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def normalize_input_image(array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    We normalize the input image tensor by dividing by 255.\n",
    "    \"\"\"\n",
    "    return 1 / 255 * array "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79bb73-f9f8-46bd-9af0-45d5cb2872f8",
   "metadata": {},
   "source": [
    "## Full network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60451b7f-405e-4045-a88e-19bbefec93ac",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db5a120f-a5d7-4e81-af60-a4b78ffe619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (2, 1, 30, 30) \n",
    "num_filters = [1, 16, 8]\n",
    "filter_conv_row, filter_conv_col = (3, 3)\n",
    "\n",
    "\n",
    "num_iterations = 1\n",
    "learning_rate = 0.1\n",
    "lambda_reg = 0.01\n",
    "num_samples = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "732b963d-1853-4102-a770-9d947cb8b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = np.transpose(np.array([\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "]))\n",
    "#print(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91a98b27-8a7f-4f50-bb52-d90819a7b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "input_dimension_mlp = int(((input_size[2] - 3 + 1) / 2 - 3 + 1) **2 / 4 * num_filters[-1])\n",
    "print(input_dimension_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "eb7a9718-7091-49e8-9725-4e1cb7f23a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.randint(0, 255, input_size)\n",
    "array = normalize_input_image(array=array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba449898-800e-45ef-b6f8-9c96bf508aec",
   "metadata": {},
   "source": [
    "### First convolution module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "87acfe4c-15d8-49a8-9772-2e0e72d71db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8b5449ab-69de-4945-b642-94fe9d3dbe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 0\n",
    "array_conv_one_shape = array.shape[1] - 3 + 1\n",
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage+1]\n",
    "filter_convolution_one = np.random.randn(num_filters_new, num_filters_old, filter_conv_row, filter_conv_col)\n",
    "offset_one = np.random.rand(num_filters_new, 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8fc008a3-ebf7-4435-9a9d-87fb214c8c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15284299850463867\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "convolution_matrix_one = create_convolution_matrix(array.shape, \n",
    "                                               filter_convolution_one,\n",
    "                                              offset_one)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d0c5b9c9-6105-4f42-a9e2-4b90ac34244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055594444274902344\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "array_extended_by_one = np.concatenate([array.flatten(), np.array([1])])\n",
    "array_conv_one = 1/num_filter_old * convolution_forward(array=array_extended_by_one, conv_matrix=convolution_matrix_one)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "19db583f-74a3-44aa-ac65-f81cb9402220",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_one_backpropagation_update = backpropagation_update_matrix(array=array,\n",
    "                             num_filters_old=num_filters_old,\n",
    "                             num_filters_new=num_filters_new,\n",
    "                             array_conv_shape=array_conv_one_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f4755b11-a1fe-4f8b-a333-7258552eb184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12544, 160)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_one_backpropagation_update.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "18e3fb15-da44-49f3-bc01-404d2d89cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_conv_one = array_conv_one.reshape((num_filters_new, array_conv_one_shape, array_conv_one_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f9aef0af-b4e4-4a82-ad2c-14b033404b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004267692565917969\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "max_pooling_one_indices, max_pooling_one = max_pooling_forward(array=array_conv_one)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b95564a7-842e-435f-b2fb-d5f6b9f18526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19289326667785645\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "max_pooling_one_backward = max_pooling_backward(array_shape=array_conv_one.shape, array_max_indices=max_pooling_one_indices)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f2abfde5-0987-4912-9d5d-905794a1e42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3136, 12544)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pooling_one_backward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1c8d9081-bb8f-4fda-b6f8-fd02fd174dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 14, 14)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pooling_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b1bfe81d-97f8-40d9-b227-dbb8f1337494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001712799072265625\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "batch_normalization_one = batch_normalization_forward(array=max_pooling_one.flatten())\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "880069e3-b180-448a-8bf9-2dbd7b895c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.64130684, -0.65681933,  0.71633762, ..., -0.56908925,\n",
       "       -0.25821053, -0.7853155 ])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_normalization_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "497d8df1-883e-4d99-9096-3d28170aa149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1548752784729004\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "batch_normalization_one_backpropagation = batch_normalization_backward(array=batch_normalization_one)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "35f2d9c5-50af-4c88-a025-1e849ee16b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3136, 3136)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_normalization_one_backpropagation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cd080ff5-2b35-4039-8175-3f52f83e05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_two = batch_normalization_one.reshape(max_pooling_one.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f3367a22-cb8a-418b-8c59-9a72786162e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 14, 14)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_two.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27273139-6bc1-4eef-b4e0-cdb641999b9f",
   "metadata": {},
   "source": [
    "### Second convolution module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2f0a2385-414b-479d-b44b-91a7951d58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 1\n",
    "array_conv_two_shape = array_two.shape[1] - 3 + 1\n",
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage+1]\n",
    "filter_convolution_two = np.random.randn(num_filters_new, num_filters_old, filter_conv_row, filter_conv_col)\n",
    "offset_two = np.random.rand(num_filters_new, 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c671b2b-d530-493c-b2e3-ccb9b3371358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05913233757019043\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "convolution_matrix_two = create_convolution_matrix(array_two.shape, \n",
    "                                               filter_convolution_two,\n",
    "                                              offset_two)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84f001a5-34e6-4ea7-9f95-0dfc8a7e7721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 3137)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_matrix_two.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b44fe8e-8dc2-42ac-8c11-95b7017a375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056105852127075195\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "array_two_extended_by_one = np.concatenate([array_two.flatten(), np.array([1])])\n",
    "array_conv_two = convolution_forward(array=array_two_extended_by_one, conv_matrix=convolution_matrix_two)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13352179-8206-47f8-abca-eccf473323eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_two_backpropagation_update = backpropagation_update_matrix(array=array_two,\n",
    "                             num_filters_old=num_filters_old,\n",
    "                             num_filters_new=num_filters_new,\n",
    "                             array_conv_shape=array_conv_two_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7c91b2b-e1a5-4995-ab20-754781ef2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 1160)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_two_backpropagation_update.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1d09a12-4a41-47ee-be12-e993cd0843d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_two_backward = 1/num_filter_old * convolution_backward(convolution_matrix=convolution_matrix_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3199b29-83f2-4a5b-8050-88285edbb183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 3136)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_two_backward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2445ece-bf8f-45fe-8c1d-edc870d9442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_conv_two = array_conv_two.reshape((num_filters_new, array_conv_two_shape, array_conv_two_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "158bc362-f950-47c0-a4ac-58f464ff9c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00021314620971679688\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "max_pooling_two_indices, max_pooling_two = max_pooling_forward(array=array_conv_two)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08268722-a5e9-4123-a5a8-8f361079adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006783008575439453\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "max_pooling_two_backward = max_pooling_backward(array_shape=array_conv_two.shape, array_max_indices=max_pooling_two_indices)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd943b97-b0a4-4d10-8979-52155b5e80f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002460956573486328\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "batch_normalization_two = batch_normalization_forward(array=max_pooling_two.flatten())\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f99c79aa-1e0b-49e6-b127-3ee3bf422416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006890296936035156\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "batch_normalization_two_backpropagation = batch_normalization_backward(array=batch_normalization_two)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68cd7ec4-e477-4b01-b694-453f991d1f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_three = batch_normalization_two.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6dcb167-ddc1-4b63-b1fd-ffae5a268866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_normalization_two.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df463cc-22e9-4fef-af85-f4b4085c2909",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "93613104-9744-4be8-9c76-4ca844db58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def extend_input_by_one_vector(x_input: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    height, width = x_input.shape\n",
    "    vector_extended = np.ones((height + 1, width))\n",
    "    vector_extended[:height, :width] = x_input\n",
    "    return vector_extended\n",
    "\n",
    "@jit\n",
    "def apply_sigmoid(x_input: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x_input))\n",
    "\n",
    "\n",
    "@jit\n",
    "def forward_pass(x_input: np.ndarray,\n",
    "                weight_matrix_input_layer: np.ndarray,\n",
    "                weight_matrix_output_layer: np.ndarray) -> Tuple[np.ndarray]:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    a1 = np.dot(weight_matrix_input_layer, x_input)\n",
    "    h1 = apply_sigmoid(a1)\n",
    "    h1 = extend_input_by_one_vector(h1)\n",
    "    a2 = np.dot(weight_matrix_output_layer, h1)\n",
    "    h2 = apply_sigmoid(a2)\n",
    "\n",
    "    return (a1, h1, a2, h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9ad74027-2d5b-4b8e-9be7-53c35ce833b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_three = np.expand_dims(array_three, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226f18e-2226-40b4-b6b9-d170a71032c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = array_three.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37ddb532-dee5-4496-a85c-9c60d37c0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = [8]\n",
    "output_dimension = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9fd6bb5-6191-4262-84d1-9568627d3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix_input_layer = np.random.randn(hidden_layer[0], input_dimension + 1)\n",
    "weight_matrix_output_layer = np.random.randn(output_dimension, hidden_layer[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dce39-06a4-4b37-bfe7-281ef91c1f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.transpose(array_three)\n",
    "x_input = extend_input_by_one_vector(x_input=x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abd51612-d3f7-4ae8-bfc9-97c1d55f62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, h1, a2, h2 = forward_pass(x_input=x_input,\n",
    "                                          weight_matrix_input_layer=weight_matrix_input_layer,\n",
    "                                          weight_matrix_output_layer=weight_matrix_output_layer)\n",
    "\n",
    "update_weights_two = 0\n",
    "update_weights_one = 0\n",
    "i = 0\n",
    "backward_one = h2[:,i] - y_label[:,i]\n",
    "update_weights_two += np.stack([backward_one[j] * h1[:,i] for j in range(output_dimension)], axis=0).flatten()\n",
    "\n",
    "update_weights_two = -1/1 * update_weights_two\n",
    "\n",
    "backward_two = np.dot(np.transpose(backward_one), weight_matrix_output_layer[:,:-1])\n",
    "backward_three = backward_two * (h1[:-1,i] * (1 - h1[:-1,i]))\n",
    "update_weights_one += np.stack([backward_three[j] * x_input[:,i] for j in range(hidden_layer[0])], axis=0).flatten()\n",
    "\n",
    "update_weights_one = -1/1 * update_weights_one\n",
    "\n",
    "backward_four = np.dot(np.transpose(backward_three), weight_matrix_input_layer[:,:-1])\n",
    "weight_matrix_output_layer = (weight_matrix_output_layer.flatten() \\\n",
    "                                  + learning_rate * update_weights_two).reshape(weight_matrix_output_layer.shape)\n",
    "weight_matrix_input_layer = (weight_matrix_input_layer.flatten() \\\n",
    "                                  + learning_rate * update_weights_one).reshape(weight_matrix_input_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "661f0441-d1b0-4518-ac08-d50a20ecd230",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp1 = np.dot(backward_four, batch_normalization_two_backpropagation)\n",
    "bp2 = np.dot(bp1, max_pooling_two_backward)\n",
    "bp3 = np.dot(bp2, convolution_two_backward)\n",
    "update_second_conv_weights = -1/1 * np.dot(bp2, convolution_two_backpropagation_update)\n",
    "update_second_conv_weights_reshaped = update_second_conv_weights[:-num_filters[2]].reshape(num_filters[2], num_filters[1], 3, 3)\n",
    "filter_convolution_two = filter_convolution_two + learning_rate * update_second_conv_weights_reshaped\n",
    "offset_two = offset_two + learning_rate * update_second_conv_weights[-num_filters[2]:]\n",
    "bp4 = np.dot(bp3, batch_normalization_one_backpropagation)\n",
    "bp5 = np.dot(bp4, max_pooling_one_backward)\n",
    "update_first_conv_weights = -1/1 * np.dot(bp5, convolution_one_backpropagation_update)\n",
    "update_first_conv_weights_reshaped = update_first_conv_weights[:-num_filters[1]].reshape(num_filters[1], num_filters[0], 3, 3)\n",
    "filter_convolution_one = filter_convolution_one + learning_rate * update_first_conv_weights_reshaped\n",
    "offset_one = offset_one + learning_rate * update_first_conv_weights[-num_filters[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1abfa-3658-41d7-b2e8-9109272b2e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185ba8d-fcf8-4720-ba75-4b1e62d735c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550934c-4489-4fe5-8960-fd41bd24c655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0910c88-13ec-43e2-8024-78e5b83cae5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd732d6a-2947-4139-a513-18c033f14e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff524c08-537a-4fca-8889-04ae121856a6",
   "metadata": {},
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b19df961-7033-4247-aef3-035cef535f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = array.copy()\n",
    "array_input = arrays[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6bb12fd1-1be9-4b54-9c51-1bffe1460c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 0\n",
    "array_conv_one_shape = array_input.shape[1] - 3 + 1\n",
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage+1]\n",
    "filter_convolution_one = np.random.randn(num_filters_new, num_filters_old, filter_conv_row, filter_conv_col)\n",
    "offset_one = np.random.rand(num_filters_new, 1).flatten()\n",
    "\n",
    "stage = 1\n",
    "array_conv_two_shape = array_two.shape[1] - 3 + 1\n",
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage+1]\n",
    "filter_convolution_two = np.random.randn(num_filters_new, num_filters_old, filter_conv_row, filter_conv_col)\n",
    "offset_two = np.random.rand(num_filters_new, 1).flatten()\n",
    "\n",
    "hidden_layer = [8]\n",
    "output_dimension = 10\n",
    "weight_matrix_input_layer = np.random.randn(hidden_layer[0], input_dimension_mlp + 1)\n",
    "weight_matrix_output_layer = np.random.randn(output_dimension, hidden_layer[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a450ecf0-8df4-4d2f-a18a-41a89ac7bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jit\n",
    "def train(num_epochs: int,\n",
    "         num_filters: list,\n",
    "         filter_convolution_one: np.ndarray,\n",
    "         filter_convolution_two: np.ndarray,\n",
    "         offset_one: np.ndarray,\n",
    "         offset_two: np.ndarray,\n",
    "         arrays: np.ndarray,\n",
    "         weight_matrix_input_layer: np.ndarray,\n",
    "         weight_matrix_output_layer: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    batch_size = arrays.shape[0]\n",
    "    for k in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        update_weights_two = 0\n",
    "        update_weights_one = 0\n",
    "        update_second_conv_weights = 0\n",
    "        update_first_conv_weights = 0\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            array = arrays[b]\n",
    "            stage = 0\n",
    "            array_conv_one_shape = array.shape[1] - 3 + 1\n",
    "            num_filters_old = num_filters[stage]\n",
    "            num_filters_new = num_filters[stage + 1]\n",
    "            convolution_matrix_one = create_convolution_matrix(array.shape, \n",
    "                                                           filter_convolution_one,\n",
    "                                                          offset_one)\n",
    "\n",
    "            \n",
    "            array_extended_by_one = np.concatenate([array.flatten(), np.array([1])])\n",
    "            \n",
    "            array_conv_one = 1/num_filter_old * convolution_forward(array=array_extended_by_one, conv_matrix=convolution_matrix_one)\n",
    "            \n",
    "            convolution_one_backpropagation_update = backpropagation_update_matrix(array=array,\n",
    "                                         num_filters_old=num_filters_old,\n",
    "                                         num_filters_new=num_filters_new,\n",
    "                                         array_conv_shape=array_conv_one_shape)\n",
    "            \n",
    "            array_conv_one = array_conv_one.reshape((num_filters_new, array_conv_one_shape, array_conv_one_shape))\n",
    "            \n",
    "            max_pooling_one_indices, max_pooling_one = max_pooling_forward(array=array_conv_one)\n",
    "            max_pooling_one_backward = max_pooling_backward(array_shape=array_conv_one.shape, array_max_indices=max_pooling_one_indices)\n",
    "            \n",
    "            batch_normalization_one = batch_normalization_forward(array=max_pooling_one.flatten())\n",
    "            batch_normalization_one_backpropagation = batch_normalization_backward(array=batch_normalization_one)\n",
    "            \n",
    "            array_two = batch_normalization_one.reshape(max_pooling_one.shape)\n",
    "            \n",
    "            stage = 1\n",
    "            array_conv_two_shape = array_two.shape[1] - 3 + 1\n",
    "            num_filters_old = num_filters[stage]\n",
    "            num_filters_new = num_filters[stage + 1]\n",
    "            convolution_matrix_two = create_convolution_matrix(array_two.shape, \n",
    "                                                           filter_convolution_two,\n",
    "                                                          offset_two)\n",
    "            convolution_two_backward = 1/num_filter_old * convolution_backward(convolution_matrix=convolution_matrix_two)\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            array_two_extended_by_one = np.concatenate([array_two.flatten(), np.array([1])])\n",
    "            \n",
    "            \n",
    "            array_conv_two = convolution_forward(array=array_two_extended_by_one, conv_matrix=convolution_matrix_two)\n",
    "            convolution_two_backpropagation_update = backpropagation_update_matrix(array=array_two,\n",
    "                                         num_filters_old=num_filters_old,\n",
    "                                         num_filters_new=num_filters_new,\n",
    "                                         array_conv_shape=array_conv_two_shape)\n",
    "            \n",
    "            array_conv_two = array_conv_two.reshape((num_filters_new, array_conv_two_shape, array_conv_two_shape))\n",
    "            \n",
    "            max_pooling_two_indices, max_pooling_two = max_pooling_forward(array=array_conv_two)\n",
    "            max_pooling_two_backward = max_pooling_backward(array_shape=array_conv_two.shape, array_max_indices=max_pooling_two_indices)\n",
    "            \n",
    "            batch_normalization_two = batch_normalization_forward(array=max_pooling_two.flatten())\n",
    "            batch_normalization_two_backpropagation = batch_normalization_backward(array=batch_normalization_two)\n",
    "            \n",
    "            array_three = batch_normalization_two.flatten()\n",
    "            array_three = np.expand_dims(array_three, axis=0)\n",
    "            \n",
    "            x_input = np.transpose(array_three)\n",
    "            x_input = extend_input_by_one_vector(x_input=x_input)\n",
    "            \n",
    "            a1, h1, a2, h2 = forward_pass(x_input=x_input,\n",
    "                                                      weight_matrix_input_layer=weight_matrix_input_layer,\n",
    "                                                      weight_matrix_output_layer=weight_matrix_output_layer)\n",
    "            \n",
    "\n",
    "            backward_one = (h2[:,0] - y_label[:,b])\n",
    "            update_weights_two += np.stack([backward_one[j] * h1[:,0] for j in range(output_dimension)], axis=0).flatten()\n",
    "            \n",
    "            #update_weights_two = -1/batch_size * update_weights_two\n",
    "            \n",
    "            backward_two = np.dot(np.transpose(backward_one), weight_matrix_output_layer[:,:-1])\n",
    "            backward_three = backward_two * (h1[:-1,0] * (1 - h1[:-1,0]))\n",
    "            update_weights_one += np.stack([backward_three[j] * x_input[:,0] for j in range(hidden_layer[0])], axis=0).flatten()\n",
    "            \n",
    "            #update_weights_one = -1/batch_size * update_weights_one\n",
    "            \n",
    "            backward_four = np.dot(np.transpose(backward_three), weight_matrix_input_layer[:,:-1])\n",
    "            #weight_matrix_output_layer = (weight_matrix_output_layer.flatten() \\\n",
    "                                              #+ learning_rate * update_weights_two).reshape(weight_matrix_output_layer.shape)\n",
    "            #weight_matrix_input_layer = (weight_matrix_input_layer.flatten() \\\n",
    "                                              #+ learning_rate * update_weights_one).reshape(weight_matrix_input_layer.shape)\n",
    "            \n",
    "            bp1 = np.dot(backward_four, batch_normalization_two_backpropagation)\n",
    "            bp2 = np.dot(bp1, max_pooling_two_backward)\n",
    "            bp3 = np.dot(bp2, convolution_two_backward)\n",
    "            update_second_conv_weights += np.dot(bp2, convolution_two_backpropagation_update)\n",
    "            #update_second_conv_weights_reshaped = update_second_conv_weights[:-num_filters[2]].reshape(num_filters[2], num_filters[1], 3, 3)\n",
    "            #filter_convolution_two = filter_convolution_two + learning_rate * update_second_conv_weights_reshaped\n",
    "            #offset_two = offset_two + learning_rate * update_second_conv_weights[-num_filters[2]:]\n",
    "            bp4 = np.dot(bp3, batch_normalization_one_backpropagation)\n",
    "            bp5 = np.dot(bp4, max_pooling_one_backward)\n",
    "            update_first_conv_weights += np.dot(bp5, convolution_one_backpropagation_update)\n",
    "            #update_first_conv_weights_reshaped = update_first_conv_weights[:-num_filters[1]].reshape(num_filters[1], num_filters[0], 3, 3)\n",
    "            #filter_convolution_one = filter_convolution_one + learning_rate * update_first_conv_weights_reshaped\n",
    "            #offset_one = offset_one + learning_rate * update_first_conv_weights[-num_filters[1]:]\n",
    "            \n",
    "        end_time = time.time()\n",
    "        print(f\"Processing time for one epoch: {end_time - start_time}\")\n",
    "        #print(f\"Probability: {h2[0,0]}\")\n",
    "\n",
    "        \n",
    "        update_weights_two = -1/batch_size * update_weights_two\n",
    "\n",
    "        update_weights_one = -1/batch_size * update_weights_one\n",
    "\n",
    "        weight_matrix_output_layer = (weight_matrix_output_layer.flatten() \\\n",
    "                                      + learning_rate * update_weights_two).reshape(weight_matrix_output_layer.shape)\n",
    "        weight_matrix_input_layer = (weight_matrix_input_layer.flatten() \\\n",
    "                                      + learning_rate * update_weights_one).reshape(weight_matrix_input_layer.shape)\n",
    "\n",
    "        update_second_conv_weights = -1/batch_size * update_second_conv_weights\n",
    "        update_second_conv_weights_reshaped = update_second_conv_weights[:-num_filters[2]].reshape(num_filters[2], num_filters[1], 3, 3)\n",
    "        filter_convolution_two = filter_convolution_two + learning_rate * update_second_conv_weights_reshaped\n",
    "        offset_two = offset_two + learning_rate * update_second_conv_weights[-num_filters[2]:]\n",
    "\n",
    "        update_first_conv_weights = -1/batch_size * update_first_conv_weights\n",
    "        update_first_conv_weights_reshaped = update_first_conv_weights[:-num_filters[1]].reshape(num_filters[1], num_filters[0], 3, 3)\n",
    "        filter_convolution_one = filter_convolution_one + learning_rate * update_first_conv_weights_reshaped\n",
    "        offset_one = offset_one + learning_rate * update_first_conv_weights[-num_filters[1]:]\n",
    "    \n",
    "    return weight_matrix_output_layer, weight_matrix_input_layer, filter_convolution_two, offset_two, filter_convolution_one, offset_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ef8433fe-b6eb-4fa3-a7e1-017553b16471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2b44d76a-347d-428c-93ef-40a0de791941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time for one epoch: 1.3677456378936768\n",
      "Processing time for one epoch: 1.3158118724822998\n",
      "Processing time for one epoch: 1.63834547996521\n",
      "Processing time for one epoch: 1.3010611534118652\n",
      "Processing time for one epoch: 1.7076952457427979\n",
      "Processing time for one epoch: 1.627326488494873\n",
      "Processing time for one epoch: 1.772806167602539\n",
      "Processing time for one epoch: 1.5833828449249268\n",
      "Processing time for one epoch: 1.7358715534210205\n",
      "Processing time for one epoch: 1.9203119277954102\n"
     ]
    }
   ],
   "source": [
    "weight_matrix_output_layer, weight_matrix_input_layer, filter_convolution_two, offset_two, filter_convolution_one, offset_one = train(num_epochs=10,\n",
    "      num_filters=num_filters,\n",
    "         filter_convolution_one=filter_convolution_one,\n",
    "         filter_convolution_two=filter_convolution_two,\n",
    "         offset_one=offset_one,\n",
    "         offset_two=offset_two,\n",
    "         arrays=arrays,\n",
    "         weight_matrix_input_layer=weight_matrix_input_layer,\n",
    "         weight_matrix_output_layer=weight_matrix_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "59172135-e231-44cf-9bd5-4698e1378ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "685ac0b4-242f-44bd-adb0-b4f6be141eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_input = arrays[b]\n",
    "stage = 0\n",
    "array_conv_one_shape = array_input.shape[1] - 3 + 1\n",
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage + 1]\n",
    "convolution_matrix_one = create_convolution_matrix(array_input.shape, \n",
    "                                               filter_convolution_one,\n",
    "                                              offset_one)\n",
    "array_extended_by_one = np.concatenate([array_input.flatten(), np.array([1])])\n",
    "array_conv_one = 1/num_filter_old * convolution_forward(array=array_extended_by_one, conv_matrix=convolution_matrix_one)\n",
    "array_conv_one = array_conv_one.reshape((num_filters_new, array_conv_one_shape, array_conv_one_shape))\n",
    "max_pooling_one_indices, max_pooling_one = max_pooling_forward(array=array_conv_one)\n",
    "batch_normalization_one = batch_normalization_forward(array=max_pooling_one.flatten())\n",
    "array_two = batch_normalization_one.reshape(max_pooling_one.shape)\n",
    "stage = 1\n",
    "array_conv_two_shape = array_two.shape[1] - 3 + 1\n",
    "num_filters_old = num_filters[stage]\n",
    "num_filters_new = num_filters[stage + 1]\n",
    "convolution_matrix_two = create_convolution_matrix(array_two.shape, \n",
    "                                               filter_convolution_two,\n",
    "                                              offset_two)\n",
    "array_two_extended_by_one = np.concatenate([array_two.flatten(), np.array([1])])\n",
    "array_conv_two = convolution_forward(array=array_two_extended_by_one, conv_matrix=convolution_matrix_two)\n",
    "array_conv_two = array_conv_two.reshape((num_filters_new, array_conv_two_shape, array_conv_two_shape))\n",
    "max_pooling_two_indices, max_pooling_two = max_pooling_forward(array=array_conv_two)\n",
    "batch_normalization_two = batch_normalization_forward(array=max_pooling_two.flatten())\n",
    "array_three = batch_normalization_two.flatten()\n",
    "array_three = np.expand_dims(array_three, axis=0)\n",
    "x_input = np.transpose(array_three)\n",
    "x_input = extend_input_by_one_vector(x_input=x_input)\n",
    "a1, h1, a2, h2 = forward_pass(x_input=x_input,\n",
    "                                          weight_matrix_input_layer=weight_matrix_input_layer,\n",
    "                                          weight_matrix_output_layer=weight_matrix_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f423a94a-7551-4db8-b15c-bc13c7ed8d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47280402],\n",
       "       [0.10461708],\n",
       "       [0.52024437],\n",
       "       [0.04577035],\n",
       "       [0.13230358],\n",
       "       [0.10674013],\n",
       "       [0.10325253],\n",
       "       [0.08217306],\n",
       "       [0.05620791],\n",
       "       [0.09387318]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f77514-1586-4403-901c-577f6cd03f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "076699e0-a64e-4a16-9e01-09e3c17a01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array_two_flatten = array_two.flatten()\n",
    "    \n",
    "#array_two_extended_by_one = np.zeros(array_two_flatten.size + 1)\n",
    "    \n",
    "#array_two_extended_by_one[:array_two_flatten.size] = array_two_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cb92b-d329-4030-a98a-9287f69fa468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
